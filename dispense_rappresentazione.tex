\documentclass[11pt]{article}


\usepackage{etex}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage[a4paper]{geometry}
\usepackage[pdftex]{graphicx}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{paralist}
\usepackage{subfig}
\usepackage{array}
\usepackage{xy}
\usepackage{multicol}
%\usepackage{slashbox}
\usepackage{fancyhdr}
\usepackage{makeidx}
\usepackage{hyperref}
\usepackage{wrapfig}
\usepackage[T1,OT1]{fontenc} 
\usepackage[nohug,small]{diagrams}


\usepackage{grffile}
\usepackage{tikz}
\usepackage{pgf,tikz}
\usetikzlibrary{shapes.geometric,calc}

\usetikzlibrary{arrows}
\topmargin 0cm
\oddsidemargin 0cm
\evensidemargin 0cm
\textwidth 16.5cm
\textheight	23.5cm
\marginparwidth 2cm
\marginparpush 2cm



\title{Dispense del corso di Teoria della Rappresentazione}
\author{Fabio Zoratti}
\date{\today}



\makeindex

\theoremstyle{plain}
\newtheorem{thm}{Teorema}[section]
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposizione}
\newtheorem{post}[thm]{Postulato}
\newtheorem*{cor}{Corollario}

\theoremstyle{definition}
\newtheorem{defn}{Definizione}[section]
\newtheorem{exmp}{Esempio}[section]
\newtheorem{prob}{Problema}[section]
\newtheorem{hint}{Suggerimento}[section]
\newtheorem{sol}{Soluzione}[section]
\newtheorem*{rem}{Osservazione}

\theoremstyle{remark}
\newtheorem*{note}{Nota}





\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\dsum}{\displaystyle\sum}
\newcommand{\dint}{\displaystyle\int}






















\begin{document}
\maketitle
\tableofcontents


PROVA SCRITTURA CONTEMPORANEA

\newpage
\section{Teoria dei gruppi}

\begin{defn}[Gruppo] Un gruppo è un insieme dotato di un'operazione binaria $\cdot : G\times G \to G$ che gode delle seguenti proprietà:
\begin{enumerate}
	\item Associatività: presi comunque $a,b,c\in G$ vale che $(a\cdot b)\cdot c = a\cdot(b\cdot c)$
	\item Esiste $e\in G$, chiamato \emph{unità}, o \emph{identità}, o \emph{elemento neutro}, tale che $\forall a\in G$ vale $e\cdot a = a = a\cdot e$
	\item Per ogni $a\in G$ esiste un $a'$ tale che $a'\cdot a$ e $a\cdot a'$ sono unità, ovvero si comportano come l'elemento $e$ al punto precedente.
		  Un tale $a'$ si dice \emph{inverso} di $a$.
\end{enumerate}
Per comodità di solito si omette il puntino. Se $G$ è finito, $card(G) = n$, si dice che $G$ ha \emph{ordine} $n$.
\end{defn}

\paragraph{Esempi}
\begin{enumerate}
	\item $\mathbb{Z}, \mathbb{Q}, \mathbb{R}, \mathbb{C}$ con l'operazione di somma.
	\item $\mathbb{Q}^*, \mathbb{R}^*, \mathbb{C}^*$ con l'operazione di moltiplicazione (senza lo 0).
	\item $GL_n(\mathbb{R})$ oppure $GL(V)$
	\item $f:I\to I $ biunivoca, con $I$ insieme e con l'operazione di composizione. Nel caso in cui $I$ sia un insieme finito, tanto vale scegliere $I = \{1,2,3,\ldots, n\}$. In tal caso questo gruppo si chiama $S_n$.
\end{enumerate}

\paragraph{Alcuni teoremi elementari}
\begin{enumerate}
	\item L'unità $e$ è unica.
	
	Dimostrazione: supponiamo che $e$ ed $e'$ siano entrambe unità. Allora vale
	
	\[e = ee' = e' \]
	
	\item Dato $a\in G$, l'inverso di $a$ è unico (e usualmente si denota con $a^{-1}$).

	Dimostrazione: supponiamo che $a', a''$ siano entrambi inversi di $a$. Allora
		
	\[(a' a)a'' = a'(aa'') \implies e a'' = a' e \implies a'' = a' \]
	
	\item Dati $a_1, a_2, \ldots, a_n$, il prodotto $a_1\cdot a_2 \cdots\cdot a_n$ è ben definito senza bisogno di parentesi.
	\item Se $ab = e$, allora anche $ba = e$, dunque $a$ e $b$ sono uno l'inverso dell'altro.

	Dimostrazione: $ba = bae = babb^{-1} = beb^{-1} = bb^{-1} = e$.
	
	\item Dato un intero positivo $k$ e un elemento $a\in G$, definiamo $a^k=\underbrace{a\cdot a \cdots\cdot a}_{k\text{ volte}}$.
	Inoltre poniamo $a^0 = e$ e infine $a^{-k} = (a^{-1})^k$, così abbiamo definito le potenze con esponente in $\Z$.
	Non è difficile dimostrare che, se $k,h$ sono interi (non necessariamente positivi), valgono le usuali proprietà: 
	\[a^{k+h} = a^k \cdot a^h \quad\quad\quad (a^k)^h = a^{kh} \]
	Però non è vero in generale che $(ab)^k = a^kb^k$ (sarebbe vero se l'operazione fosse commutativa). Osserviamo infine che 
	\[ (ab)^{-1} = b^{-1}a^{-1}\]
	infatti $(ab)(b^{-1} a^{-1}) = a(bb^{-1})a^{-1} = aea^{-1} = aa^{-1} = e$.
\end{enumerate}



\begin{defn}[Sottogruppo]
Sia $G$ un gruppo, $H\subseteq G$ si dice sottogruppo di $G$ se:
\begin{itemize}
	\item $e\in H$
	\item $x,y\in H \implies xy\in H$
	\item $x\in H \implies x^{-1}\in H$
\end{itemize}
e si indica $H \leq G$. In altre parole $H$ è sottogruppo se,
ereditando l'operazione di $G$, è esso stesso un gruppo.
\end{defn}

\begin{exmp}[Sottogruppo generato da un elemento]
Sia $G$ un gruppo e $a$ un suo elemento. L'insieme delle potenze di $a$, ovvero $\{a^k | k\in\Z\}$, è un sottogruppo di $G$,
che di solito viene denotato con $\langle a\rangle$.
\end{exmp}

\begin{rem}
Se $G$ è gruppo, $a\in G$ ed esiste un intero $n>0$ tale che $a^n=e$, allora tutti gli elementi di $\langle a\rangle$ sono della forma
$a^k$ per qualche $0\le k < n$. Infatti se si considera un qualsiasi $a^s$ con $s\in\Z$, si può scrivere $s=nq+r$ con $0\le r<n$.
Allora \[a^s=a^{nq+r} = (a^n)^qa^r = e^qa^r = a^r\]
Se $n$ è il minimo intero positivo tale che $a^n=e$, allora si dice che $a$ ha \emph{ordine} $n$. In tal caso è facile verificare che
l'insieme $\langle a\rangle$ contiene esattamente $n$ elementi distinti, ovvero $a^0, a^1, \dots a^{n-1}$.
Infatti, se fosse $a^i=a^j$ con $0\le i<j<n$, allora $a^{j-i}=e$, che sarebbe assurdo siccome $0<j-i<n$.

Se $\langle a\rangle$ è finito (il che è certo se ad esempio $G$ è finito) allora di sicuro esiste $n>0$ tale che $a^n=e$. Infatti basta prendere $0\le i < j$
tali che $a^i = a^j$ e osservare che $a^{j-i} = e$. Questi $i$ e $j$ esistono per forza perché se tutte le potenze fossero distinte allora $\langle a\rangle$ sarebbe infinito.
\end{rem}


\begin{defn}[Sottogruppo normale]
Sia $G$ un gruppo, $H \leq G$ si dice \emph{normale} in $G$ se
\[
	\forall h\in H, \forall g\in G\qquad ghg^{-1}\in H
\]
e si indica $H \trianglelefteq G$.
\end{defn}

\begin{defn}[Gruppo quoziente]
NON LO SCRIVO PERCHÈ È LUNGO, ASPETTO DI VEDERE COME/SE LO DEFINISCE LUI
\end{defn}

\begin{defn}[Classi di coniugio]
Sia $G$ un gruppo, $x \in G$, la classe di coniugio di $x$ è l'insieme $\{ gxg^{-1} | g\in G \}$. Si dimostra facilmente che le classi di coniugio di tutti gli elementi di $G$ formano una partizione del gruppo stesso. Si osserva inoltre che un sottogruppo è normale se e solo se è unione di classi di coniugio (ATTENZIONE: è raro che unendo a caso classi di coniugio si ottenga un sottogruppo).
\end{defn}


\begin{exmp}[Le classi di coniugio di $GL_n(\C)$]
Nel caso del gruppo $GL_n(\C)$ due matrici stanno nella stessa classe di coniugio se e solo se sono simili, quindi per ogni classe di coniugio esiste un rappresentante canonico che è la forma di Jordan di una qualsiasi matrice nella classe (con opportune convenzioni sull'ordine dei blocchi e degli autovalori).
\end{exmp}

\begin{defn}[Centro di un gruppo]
	Sia $G$ un gruppo, il \textit{centro} di $G$ si indica con $Z(G)$ ed è il sottoinsieme degli elementi che commutano con tutto $G$:
	\[
		Z(G)=\{ h\in G\ |\ hg=gh\ \forall g\in G \}
	\]
	\`E immediato verificare che $Z(G)$ è un sottogruppo normale di $G$.

\end{defn}

\begin{defn}[Prodotto diretto di gruppi]
Siano $G$ e $H$ gruppi. Si definisce prodotto diretto di $G$ e $H$ il gruppo formato dall'insieme $G \times H = \{ (g, h) | g \in G, h \in H\}$ con l'operazione componente per componente, ovvero separatemente per i due gruppi di partenza.
\end{defn}


\begin{defn}[Omomorfismo (isomorfismo) di gruppi]
Siano $G$ ed $H$ gruppi, un'applicazione $\varphi:G\to H$ si dice \textit{omomorfismo di gruppi} se
\[
	\forall g_1,g_2\in G\qquad \varphi(g_1 g_2)=\varphi(g_1)\varphi(g_2)
\]
dove la prima moltiplicazione è fatta in $G$ mentre la seconda in $H$.
Se $\varphi$ è bigettiva, allora si dice \textit{isomorfismo}, e i due gruppi si dicono \emph{isomorfi}.
Indichiamo con $Hom(G,H)$ l'insieme degli omomorfismi da $G$ ad $H$.
\end{defn}


\begin{defn}[Azione di un gruppo su un insieme] Sia $G$ un gruppo e $I$ un insieme. Chiamiamo azione $a$ di $G$ su $I$ una funzione $a:G\times I \to I$ che rispetti la regola di composizione, ovvero che se $h,g\in G$ e $i \in I$, valga

\[ a(h,a(g,i)) = a(hg, i) \]

Normalmente si usa una notazione abbreviata in cui invece di scrivere $a(g,i)$ si scrive direttamente $g\cdot i$ o addirittura $gi$


\label{defn:azione}
\end{defn}


\begin{defn}[Azione transitiva]
Un'azione di un gruppo $G$ su un insieme $I\neq \emptyset$ si dice \textit{transitiva} se $\forall\ i,j\in I\ \exists s\in G$ t.c. $j=s\cdot i$.
\label{defn:azione transitiva}
\end{defn}

SAREBBE UTILE SCRIVERE UN COMANDO PER SCRIVERE ORB(X) SOLO CHE NON SO COME SI FA...
\begin{defn}[Orbita di un elemento]
Sia $G$ un gruppo che agisce sull'insieme $I$, dato $x\in I$ si chiama \textit{orbita} di $x$ in $G$ l'insieme $Orb_{G}(x)=\{ g\cdot x\ |\ g\in G \}$, se il gruppo utilizzato è chiaro si può scrivere semplicemente $Orb(x)$. Si osserva subito che un'azione è transitiva se e solo se induce una unica orbita.
\label{defn:orbita}
\end{defn}
\begin{rem}
	Un gruppo $G$ può agire su se stesso per coniugio, ovvero dati $g\in G$ (qui $G$ è pensato come gruppo che agisce) e $x\in G$ ($G$ pensato come insieme),
	si pone $g\cdot x = gxg^{-1}$. Non è difficile verificare che si tratta davvero di una azione.
	Osserviamo che le classi di coniugio sono le orbite degli elementi generate mediante l'azione per conugio.
\end{rem}




\begin{defn}[Azione semplicemente transitiva]
Un'azione di $G$ su un insieme $I\neq \emptyset$ si dice \textit{semplicemente transitiva}
se presi comunque $i,j\in I$ esiste un unico $s\in G$ tale che $j=s\cdot i$.
\end{defn}


\begin{defn}[Funzione $G$ equivariante]

Dato un gruppo $G$ che agisce su due insiemi $I$ e $J$, una funzione $\phi: I \to J$ si dice $G$ equivariante se 

\[ \phi(s \cdot_I i) = s \cdot_J \phi(i) \qquad \forall s \in G, \ \ \forall i \in I \]


\end{defn}


















\newpage
\subsection{Proprietà dei gruppi ciclici}

\begin{defn}[Gruppo ciclico] Un gruppo $G$ si dice ciclico se esiste un elemento $a\in G$ tale che ogni
elemento di $G$ è una potenza di $a$, ovvero $G=\langle a\rangle$. Si dice che $a$ è un generatore di $G$.
\end{defn}

\begin{rem}
Sia $G$ un gruppo ciclico di cardinalità $n$ e generatore $a$. Allora $n$ è il più piccolo intero positivo tale che $a^n = e$,
e ogni elemento di $G$ si scrive in modo unico come $a^k$ con $0\le k < n$.
\end{rem}

\begin{exmp}[Radici dell'unità]
Dato $n>0$ intero, l'insieme $\mu_n\subset \C^*$ delle radici $n$-esime dell'unità è un gruppo ciclico con $n$ elementi.
\end{exmp}

\begin{rem} Se $n$ è un intero positivo esiste (a meno di isomorfismo) un unico gruppo ciclico di cardinalità $n$.
Abbiamo già visto che esiste (basta considerare $\mu_n$),
inoltre dati due gruppi ciclici di cardinalità $n$ e generatori rispettivamente $a$ e $b$ è immediato costruire un
isomorfismo $f:\langle a\rangle\to\langle b\rangle$ ponendo $f(a^k) = b^k$ per $0\le k < n$.
\end{rem}


\begin{prop} Sia $C_n$ un gruppo ciclico di cardinalità $n$. Allora
\[ n = card(Hom(C_n,\C^*))\]
\end{prop}
\textsc{Dimostrazione:} Sia $a$ un generatore di $C_n$. Fissato $\omega\in\mu_n$ posso definire
una funzione $f:C_n\to\C^*$ ponendo $f(a^k) = \omega^k$ per $0\le k < n$.
Verifichiamo che $f\in Hom(C_n, \C^*)$. A tal fine prendiamo due elementi di $C_n$, che sono della forma $a^k, a^h$ per certi interi $0\le k,h < n$.
\[f(a^k \cdot a^h) = f(a^{k+h}) = \omega^{k+h} = \omega^k \omega^h = f(a^k)f(a^h)\]
Dunque $f$ è omomorfismo. Variando la scelta di $\omega\in\mu_n$ si producono effettivamente $n$ omomorfismi differenti (infatti se $\omega$ cambia allora cambia anche $f(a)$).
Mostriamo che non ci sono altri omomorfismi oltre a questi.
Sia $f\in Hom(C_n,\C^*)$. Visto che $a^n=e$, deve valere $f(a)^n = f(a^n) = 1$. Allora $f(a)$ deve essere una radice $n$-esima
dell'unità, che chiamiamo $\omega$. A questo punto il fatto che $f$ è omomorfismo implica che $f(a^k) = \omega^k$ per ogni intero $k$. \qed



\subsection{Proprietà dei gruppi abeliani}
\begin{defn}[Gruppo abeliano] Un gruppo $G$ si dice abeliano se l'operazione di gruppo è commutativa, cioè $\quad\forall a,b\in G\quad ab=ba$.
\end{defn}

\begin{rem} Un gruppo ciclico è sempre abeliano.
\end{rem}

Potrebbe essere utile conoscere il seguente risultato, la cui dimostrazione richiederebbe una conoscenza più approfondita della teoria dei gruppi.
\begin{thm}Ogni gruppo abeliano finito è isomorfo al prodotto diretto di gruppi ciclici.
\end{thm}

\begin{rem} Sia $G$ un gruppo abeliano. Allora 
\[ |G| = card(Hom(G,\C^*))\]

La dimostrazione si ottiene ricordando che $G$ è prodotto diretto di gruppi ciclici e facendo un ragionamento simile a quello
della proposizione analoga per gruppi ciclici.
Se invece $G$ non è abeliano allora nella formula precedente all'uguale va sostituito un $>$.
\end{rem}



\subsection{Proprietà del gruppi simmetrici}

\begin{thm}[Ogni elemento $\sigma \in S_n$ si scrive in modo unico come prodotto di cicli disgiunti a meno dell'ordine dei fattori]


\end{thm}

\begin{prop}Il segno di un ciclo di lunghezza $k$ è esattamente $(-1)^{k-1}$


\end{prop}



\subsection{Proprietà dei gruppi diedrali}

\begin{defn}[Gruppo diedrale]
L'insieme $D_n$ delle rotazioni e simmetrie di un poligono regolare di $n$ lati è un gruppo con l'operazione di composizione.
Detta $\rho$ una rotazione di $2\pi/n$ (che ha ordine $n$, e per inverso ha $\rho^{n}$) e $\sigma$ una qualunque riflessione (che ha ordine $2$), esse generano
il gruppo $D_n$, che si può quindi presentare nel seguente modo: $$D_n=\langle\rho,\sigma|\rho^n=\sigma^2=id,\ \sigma\rho\sigma=\rho^{-1}\rangle$$
\end{defn}

\begin{rem}
 Le $n$ potenze distinte di $\rho$ sono tutte e sole le rotazioni di $D_n$, mentre gli elementi della forma $\sigma\rho^{i},\ i=0,1,..,n-1$ 
 sono tutte e sole le riflessioni. 
\end{rem}

\begin{rem}
 Si dimostra facilmente che la relazione $\sigma\rho\sigma=\rho^{-1}$ è verificata da qualsiasi rotazione $\rho$
 e qualsiasi riflessione $\sigma$.
\end{rem}







\newpage
\section{Algebra lineare}
In questa sezione diamo alcune definizioni e teoremi di algebra lineare che sono stati utilizzati nel corso o che sono utili per avere una visione d'insieme di certi argomenti. Non saranno presenti le dimostrazioni che possono essere trovate su molti libri di algebra lineare.
\begin{thm}[Diagonalizzazione simultanea]
\label{thm:diag_sim}
	Date due matrici $M, N\in \mathcal{M}(n,n,\K)$, diremo che sono \textit{simultaneamente diagonalizzabili} se esiste una base comune di autovettori per entrambe.\\
	Date $M, N\in \mathcal{M}(n,n,\K)$, se esse commutano e sono entrambe diagonalizzabili allora sono simultaneamente diagonalizzabili.
\end{thm}
\begin{cor}
	Date $M_1,\ldots,M_k \in \mathcal{M}(n,n,\K)$, se $M_iM_j=M_jM_i\ \forall\ i, j$ e ogni $M_i$ è diagonalizzabile, allora esiste una base comune di autovettori per tutte quante.
\end{cor}


\begin{defn}[Ideale di un endomorfismo]
	Se $p(x)=a_n x^n+\ldots+a_0$, allora scriviamo $p(f)$ per intendere $a_nf^n+\ldots+a_0f^0$ dove $f^0=Id$ e $f^k=\underbrace{f\circ\ldots\circ f}_{k \text{ volte}}$.\\
	Sia $V$ un $\K$-spazio vettoriale, $f:V\to V$ un endomorfismo di $V$. Definiamo \textit{ideale di $f$} l'insieme
	\[
		I(f)=\left\{ p(x)\in \K[x]\ |\ p(f)=0 \right\}
	\]
	

\end{defn}


\begin{thm}[Teorema di decomposizione primaria]
\label{thm:dec_primaria}
	Siano $V$ un $\K$-spazio vettoriale, $f:V\to V$ un endomorfismo di $V$ e $q(x)\in I(f)$. Sia $q=q_1\cdot\ldots\cdot q_k$ tale che $MCD(q_i,q_j)=1\ \forall\ i\neq j$, allora $V=Ker(q_1(f))\oplus\dots\oplus Ker(q_k(f))$ e gli addendi sono $f$-invarianti.\\
	In particolare se $f$ è triangolabile e $\lambda_1,\ldots,\lambda_k$ sono gli autovalori di $f$ con molteplicità geometrica rispettivamente $\alpha_1,\ldots,\alpha_k$, allora $V=Ker\left((f-\lambda_1 Id)^{\alpha_1}\right)\oplus\dots\oplus Ker\left((f-\lambda_k Id)^{\alpha_k}\right)$.
\end{thm}

\begin{thm}[Forma canonica di Jordan]
	Sia $M\in \mathcal{M}(n,n,\K)$ una matrice triangolabile, siano $\lambda_1,\ldots,\lambda_k$ i suoi autovalori, allora $M$ è simile alla sua \textit{forma canonica di Jordan} che è nella forma
	\begin{align*}
		&\begin{pmatrix}
			J_1 & & \\
			& \ddots & \\
			& & J_t
		\end{pmatrix}		
		&\text{ dove }J_i=\begin{pmatrix}
		                  	\lambda & 1 & & & \\
							& \lambda & 1 & & \\
		                  	& & \ddots & \ddots & \\
		                  	& & & \ddots & 1 & \\
		                  	& & & & \lambda
		                  \end{pmatrix} \text{ per qualche }\lambda \in \left\{ \lambda_1,\ldots,\lambda_k \right\}
	\end{align*}
	La dimensione e il numero di blocchi di ciascun tipo sono univocamente determinati dalla matrice $M$, ne segue che la forma canonica di Jordan è unica a meno di permutazione dei blocchi e dunque, scelta una convenzione sull'ordine dei blocchi, essa è un sistema completo di invarianti per similitudine: due matrici sono simili se e solo se hanno la stessa forma di Jordan.

\end{thm}
\begin{defn}[Forma hermitiana]
Siano $V,W$ due $\C$-spazi vettoriali, una funzione $h:V\times V\to W$ si dice \textit{forma hermitiana} se $\forall v,w,z\in V,\ \forall \alpha \in \C$ vale che NON MI RICORDO DOVE AVEVA MESSO IL CONIUGATO
\begin{gather*}
	h(v,w) = \overline{h(w,v)}\\
	h(v,\alpha w) = \alpha h(v,w)\\
	h(v+z,w)=h(v,w)+h(z,w)
\end{gather*}

\end{defn}



\newpage
\section{Algebra multilineare}
\subsection{Alcune generalizzazioni di algebra lineare}

\begin{defn}[Base di uno spazio vettoriale]
Sia $V$ uno spazio vettoriale e $I$ un insieme; una base di $V$ è una funzione $e: I \to V$ tale che 
$\forall v \in V,\  \exists!\  a: I \to \mathbb{C}$ a supporto finito per cui vale $v=\sum_{i\in I}a_i e_i$. La funzione $a$ 
valutata in $i$ prende il valore della $i$-esima coordinata del vettore $v$ nella base $e$. Questa definizione è compatibile con la 
definizione di base come insieme di vettori generatori linearmente indipendenti.
\end{defn}


\begin{lemma}
 Sia $e:I\to V$ una base di $V$ e $W$ uno spazio vettoriale. $f: I \to W$ una funzione. Allora $\exists!\  \phi: V \to W$ lineare tale che

\[\phi(e_i) = f_i \]

Inoltre $\phi$ è un isomorfismo $\Leftrightarrow$ $f$ è una base.
\end{lemma}


\subsection{Prodotto tensoriale}


% \[ \tridiag{V\times W}{ \otimes }{V\otimes W}{\phi}{Z}{f} \]
  


\begin{defn}[Prodotto tensoriale]
   Siano $V, W$ due $\mathbb{C}$-spazi vettoriali. Si dice prodotto tensore di $V$ e $W$, 
   e si indica come $V\otimes W$, uno spazio vettoriale con una funzione bilineare 
   $\otimes: V \times W \to V\otimes W$ tale che per ogni data funzione bilineare $h: V\times W \to  Z$,
   esiste unica $\phi: V\otimes W \to Z$ lineare per cui $\phi(v \otimes w)=h(v,w)$.
   Questa proprietà viene detta proprietà universale e la funzione $\otimes: V \times W \to V\otimes W$
   viene detta funzione universale.
%	\tridiag{V\times W}{ \otimes }{V \otimes W}{\phi}{Z}{f}



\label{defn:prodotto tensoriale}
\end{defn}


\begin{prop}
Se ho due prodotti tensoriali $V \otimes W$ e $V \overline{\otimes} W$, allora esiste un unico isomorfismo 
$\phi: V \otimes W \to V \overline{\otimes} W$ tale che

\[ \phi (v\otimes w) = v \overline{\otimes} w\]
\end{prop}


\begin{note}
\`E importante notare che non tutti gli elementi $z \in V \otimes W$ si scrivono come $z = v \otimes w$. In particolare, per fare un esempio concreto che mostra che questa cosa non funziona, prendiamo $W = V^*$. Vedremo fra poco che $V\otimes V^*$ è canonicamente isomorfo allo spazio delle applicazioni bilineari da $V$ in $\C$, che sappiamo scriverlo come matrici $n\times n$. Tuttavia se un elemento si scrive in termini di matrici come $z = v\otimes w$, allora la matrice associata a $z$ in una base avrà rango al massimo 1, ben lontano da coprire tutto lo spazio.
\end{note}


\begin{prop}
\[\langle\{ v \otimes w | v \in V, w \in W\} \rangle  = V \otimes W\]

\end{prop}


\begin{defn}[Prodotto tensoriale di mappe lineari]
Date $f:V \to V'$ e $g:W \to W'$ funzioni lineari, si definisce prodotto tensoriale tra $f$ e $g$ la funzione lineare $f \otimes g : V \otimes W \to V' \otimes W'$ tale che $(f \otimes g)(v \otimes w)=f(v) \otimes g(w)$ $\forall v\in V, w\in W$

\end{defn}

\begin{rem}

\[ id_V \otimes id_W = id_{V\otimes W}\]
\end{rem}




\begin{prop}

Se $e_i$ è una base di $V$ e $f_i$ è una base di $W$ allora $e_i \otimes f_j$ è una base di $V \otimes W$
\end{prop}


\begin{cor}
\[dim(V \otimes W) = dim V \cdot dim W \]

\end{cor}

















\begin{defn}
La \emph{traccia} di un elemento del prodotto tensoriale, ovvero 
\[ tr(f\otimes g)\], 
è l'unico funzionale lineare $tr: V \otimes W \to \K$ che soddisfa le proprietà:
\begin{enumerate}
\item $tr[ (v_1 \otimes w_1) (v_2 \otimes w_2) ] = tr[ (v_2 \otimes w_2) (v_1 \otimes w_1) ] $ 
\item $tr[ (id_V \otimes id_W)  ]  = \mbox{dim} V \cdot \mbox{dim} W $
\end{enumerate}
\end{defn}


\begin{thm}
Se $f:V\to V$ e $g:W\to W$ sono endomorfismi di spazi vettoriali, allora vale la formula

\[tr(f\otimes g) = tr(f) tr(g)  \]

\end{thm}

\textsc{Dimostrazione:} L'applicazione $\phi: V x W \to \K$ che manda $(f\otimes g)$ in $tr(f) tr(g)$ è bilineare, e quindi corrisponde a un funzionale $\Phi: V x W \to \K$ lineare. Bisogna verificare che soddisfa le due proprietà della definizione.  È evidente che $\Phi[ (id_V \otimes id_W)  ]  $ 


\subsection{Prodotto esterno e prodotto simmetrico}

\begin{defn}[Applicazione $r$-lineare simmetrica/alternante]
 Una applicazione $\phi: V^n \to Z$ si dice $r$-lineare se è lineare in ogni componente dopo aver fissato le altre $n-1$.

 Inoltre $\phi$ si dice simmetrica se $\phi(v_{s(1)},\ldots,v_{s(n)})=\phi(v_1,\ldots,v_n),\ \forall s \in S_n$, mentre si dice 
 alternante se $\phi(v_{s(1)},\ldots,v_{s(n)})=\mathrm{sgn}(s)\phi(v_1,\ldots,v_n),\ \forall s \in S_n$.
 
\end{defn}

\begin{prop}
 Un'applicazione $h: V^n \to W$ è alternante se e solo se $h(v_1,\ldots,v_n)=0$ se $v_i=v_j$ per qualche $i\neq j$.
 \end{prop}

 \begin{prop}
  Un'applicazione $h: V^n \to W$ è nulla se i vettori $v_1,\ldots,v_n$ sono linearmente dipendenti.
 \end{prop}

\begin{defn}[Prodotto esterno]
Sia $n$ un intero positivo, $V$ uno spazio vettoriale. Un prodotto esterno è uno spazio vettoriale indicato con $\bigwedge^n V$
dotato di una funzione $n$-lineare alternante $\wedge: V^n \to \bigwedge^n V$ che manda $(v_1,\ldots,v_n)$ in 
$v_1\wedge v_2\wedge\ldots\wedge v_n \in \bigwedge^n V$, tale che $\forall h: V^n \to Z$ $n$-lineare alternante, 
esiste unica $\phi: \bigwedge^n V \to Z $ lineare per cui vale $\phi(v_1\wedge v_2\wedge \ldots \wedge v_n)=h(v_1,\ldots,v_n)$.

\label{defn:prodotto esterno}
\end{defn}





\begin{thm}[Dimensione del prodotto esterno]
Sia $V$ uno spazio vettoriale di dimensione $n$, $\{e_i| 1 \leq i \leq n\}$ una base di $V$ e $k$ un intero positivo.
Allora l'insieme $E=\{e_{i_1} \wedge e_{i_2}\wedge \ldots \wedge e_{i_k}| 1 \leq i_1 < i_2 <\ldots< i_k \leq n\}$ è una base di $\bigwedge^k V$ 
e si ha $|E|= \binom {n}{k}$.

\label{thm:prodotto esterno}
\end{thm}


MANCANO UN SACCO DI PROPRIETA' E LE DIMOSTRAZIONI





\begin{defn}[Prodotto simmetrico]

Sia $n$ un intero positivo, $V$ uno spazio vettoriale. Un prodotto simmetrico è uno spazio vettoriale indicato con $S^n V$
dotato di una funzione $n$-lineare simmetrica $V^n \to \bigwedge^n V$ che manda $(v_1,\ldots,v_n)$ in 
$v_1 v_2\ldots v_n \in S^n V$, tale che $\forall h: V^n \to Z$ $n$-lineare simmetrica, 
esiste unica $\phi: S^n V \to Z $ lineare per cui vale $\phi(v_1 v_2 \ldots v_n)=h(v_1,\ldots,v_n)$.

\label{defn:prodotto simmetrico}
\end{defn}





\begin{thm}[Dimensione del prodotto simmetrico]

Sia $V$ uno spazio vettoriale di dimensione $n$, $\{e_i| 1 \leq i \leq n\}$ una base di $V$ e $k$ un intero positivo.
Allora l'insieme $E=\{e_{i_1} \wedge e_{i_2}\wedge\ldots \wedge e_{i_k}| 1 \leq i_1 \leq i_2 \leq\ldots\leq i_k \leq n\}$ è una base di $S^k V$ 
e si ha $|E|= \binom {n+k-1}{k}$.

\label{thm:prodotto simmetrico}
\end{thm}


\begin{defn}[Potenza simmetrica e potenza esterna di un'applicazione lineare]

Sia $f: V\to V$ un endomorfismo di uno spazio vettoriale. Definiamo 

\[\bigwedge^k f : \bigwedge^k V \to \bigwedge^k V | f(v_1 \wedge \ldots \wedge v_n) = f(v_1) \wedge \ldots \wedge f(v_n) \]

In modo analogo si definisce la potenza simmetrica.


\end{defn}




\begin{prop}
Sia $f: V \to V$ un endomorfismo di uno spazio vettoriale. Allora vale

\[ 
\begin{cases}
tr(\bigwedge^2 f ) = \dfrac{(tr(f))^2 - tr(f^2)}{2} \\
tr(S^2 f ) = \dfrac{(tr(f))^2 + tr(f^2)}{2} \\
\end{cases}
\]



\end{prop}
















\newpage
\section{Prime proprietà delle rappresentazioni}

\begin{defn}[Rappresentazione] Sia $G$ un gruppo. Una rappresentazione $\rho$ di $G$ è una coppia composta da uno spazio vettoriale di dimensione qualsiasi $V_\rho$ e una funzione $\rho: G \to GL(V_\rho)$ che manda ciascun elemento del gruppo in un'applicazione lineare di $V_\rho$, ovvero un suo endomorfismo. Affinché $\rho$ sia una rappresentazione deve essere un omomorfismo di gruppi, ovvero in parole semplici deve rispettare la regola di composizione. In formule, se $s, t \in G$ deve valere

\[ \rho(st) v = \rho(s)\rho(t) v \qquad \forall v \in V_\rho, \quad \forall s,t \in G\]

La dimensione di $V_\rho$ viene detta grado della rappresentazione.

\end{defn}

\begin{prop} $\rho(G)$ è evidentemente un sottogruppo di $GL(V_\rho)$, quindi esistono sempre inversi, potenze e tutte le cose che valgono per i gruppi.

\end{prop}


\textbf{Esempi.}
\begin{enumerate}
	\item La rappresentazione banale, di grado qualsiasi, indicata con $\rho_1$ che manda qualsiasi elemento di $g$ nell'identità di $V_\rho$, ovvero
	
	\[ \rho(s ) = id_{V_\rho} \qquad \forall s \in G\]
	\item Dato $S_n$, il segno di un elemento $s\in S_n$ è una rappresentazione di grado 1. Infatti si ha $sgn(st) = sgn(s) sgn(t)$.
	\item L'azione naturale di $S_n$ sui vettori della base. Prendiamo quindi $G = S_n$ e uno spazio vettoriale di dimensione $n$, che sarà sicuramente isomorfo a $\C^n$. Prendiamo la base canonica di $\C^n$ e la chiamiamo $e_i$. Descriviamo la rappresentazione $\rho: S_n \to GL(\C^n)$ dicendo cosa fa agli elementi della base. Per linearità si estenderà a tutto lo spazio.
	
	\[ \rho(s) e_i = e_{s(i)}\]
	
	Notare che in questo caso $deg(\rho) = n$. Notiamo inoltre che se rappresentiamo nella base canonica le matrici associate a $\rho(s)$ queste matrici sono unitarie. Inoltre, ogni colonna (e anche ogni riga) contiene esattamente un 1 e tutti gli altri sono 0.
	
	Prendiamo come esempio $S_3$ e vediamo cosa succede. Notiamo innanzitutto che $ |S_3| = 3! = 6$
	FINISCI DI SCRIVERE
\end{enumerate}








\begin{prop}
Sia $G$ un gruppo finito e $\rho: G \to GL(V_\rho)$ una sua rappresentazione. Allora $\forall g \in G$ la matrice $\rho(g)$ ammette una base di autovettori in $V_\rho$, ovvero è diagonalizzabile. Inoltre, tutti gli autovalori di $\rho(g)$ sono radici $n-$esime dell'unità.

\textsc{Nota bene:} Per ogni matrice in generale la base è diversa, quindi le varie matrici in generale \textbf{non} sono simultaneamente diagonalizzabili. In particolare, tutte le matrici $\rho(s)$ sono simultaneamente diagonalizzabili $\Leftrightarrow$ $G$ è abeliano. 

\label{prop:diagonalizzabilita rappresentazioni}
\end{prop}

\textsc{Dimostrazione:} Se $G$ è un gruppo finito, allora $\exists k | g^k = e$\footnote{Dato che $g$ è finito, se prendo l'insieme delle potenze $I = \{g^k| k\in \mathbb{Z}\}$, proprio perchè $G$ è finito si ha che $I$ ha un numero finito di elementi, quindi ci saranno $m,n \in \mathbb{Z}$ tali che $g^m = g^n = h$. Dato che nei gruppi esiste l'inverso, sarà $g^{n-m} = e$}. Dato che $\rho:G\to GL(V_\rho)$ mantiene queste proprietà in quanto omomorfismo, dovrà essere

\[ \rho(g)^k = id\]

Visto che il polinomio minimo di $\rho(g)$ non ha radici multiple, con il teorema di decomposizione primaria \eqref{thm:dec_primaria} si mostra facilmente che $\rho(g)$ è diagonalizzabile. Inoltre da questa formula è anche evidente che tutti gli autovalori di $\rho(g)$ hanno modulo $1$ e in particolare saranno radici $k-$esime dell'unità.

Ricordiamo un teorema di algebra lineare per finire l'ultima parte della dimostrazione: due endomorfismi di uno spazio vettoriale diagonalizzabili sono simultaneamente diagonalizzabili $\Leftrightarrow$ commutano. Da questo teorema segue facilmente la seconda parte dell'enunciato. \qed





\begin{defn}[Omomorfismo di rappresentazioni]
Siano $\rho$ e $\sigma$ due rappresentazioni di $G$ su $V_{\rho}$ e $V_{\sigma}$ rispettivamente, un omomorfismo di spazi vettorali $\varphi:V_{\rho}\to V_{\sigma}$ si dice \textit{omomorfismo di rappresentazioni} se
\[
	\forall\ a\in G, \forall\ v\in V_{\rho}\quad \varphi(\rho(a)(v)) = \sigma(a)(\varphi(v))
\]
oppure equivalentemente
\[
	\forall\ a\in G\quad \varphi\circ \rho(a) = \sigma(a)\circ \varphi
\]


%Siano $G, H$ due gruppi e $\rho: G \to V_\rho$ e $\sigma: H \to V_\sigma$ due loro rappresentazioni. Una funzione lineare da $V_\rho \to V_\sigma$ \footnote{Ovvero un omomorfismo da $V_\rho$ a $V_\sigma$} è un omomorfismo di rappresentazioni se rispetta la regola di composizione


%\[ \qquad \forall v,w \in V_\rho, V_\sigma\]


\end{defn}



\begin{defn}[Rappresentazioni isomorfe]
Due rappresentazioni si dicono \textit{isomorfe} se esiste un omomorfismo di rappresentazioni tra di loro che è anche bigettivo.
\end{defn}




\paragraph{Rappresentazioni di grado 1}

\begin{thm}[Le classi di isomorfismo delle rappresentazioni di grado 1 sono gli omomorfismi da $G$ in $\C^*$]


\end{thm}


\begin{exmp}[Rappresentazioni di grado 1 di $C_n$]

\end{exmp}


\begin{exmp}[Rappresentazioni di grado 1 di $S_3$]

\end{exmp}

\begin{exmp}[Rappresentazioni di grado 1 di $C_n \times C_n$]


(generalizzazione a prodotto di $C_{n_i}$)
\end{exmp}














\newpage
\subsection{Operazioni con le rappresentazioni}

\begin{defn}[Somma di rappresentazioni]

\label{defn:somma di rappresentazioni}
\end{defn}

Osservazioni:

\begin{enumerate}
\item $\rho + \sigma \cong \sigma + \rho$
\item $\rho + (\sigma + \tau) \cong (\rho + \sigma ) + \tau$
\item Esiste l'elemento neutro che è la rappresentazione di grado 0 ma non esiste l'inverso.

\end{enumerate}





\begin{defn}[Prodotto di rappresentazioni]

\label{defn:prodotto di rappresentazioni}
\end{defn}


Osservazioni:


\begin{enumerate}
\item $1\otimes \rho \cong \rho$
\item $\rho \otimes \sigma \cong \sigma \otimes \rho$
\item $0 \otimes \rho \cong 0$
\item $\rho \otimes (\sigma \otimes \tau) \cong (\rho \otimes \sigma)\otimes \tau$
\item $\rho \otimes (\sigma_1 + \sigma_2) \cong \rho \otimes \sigma_1 + \rho \otimes \sigma_2$

\end{enumerate}





\begin{defn}[Rappresentazione duale]
Sia $\rho$ una rappresentazione di $G$ su $v_\rho$. Allora la rappresentazione duale $\rho^*$ è la rappresentazione di $G$ su $v_\rho ^*$ tale che $\rho^*(s)=\rho(s^{-1})^t$
\label{defn:rappresentazione duale}
\end{defn}

\begin{note}
$\rho^*(s)=\rho(s^{-1})^t=\left(\rho(s)^{-1}\right)^t=\left(\rho(s)^t\right)^{-1}$. Inoltre, notare che la presenza di inverso e trasposto fa in modo che $\rho^*(s)$ sia una rappresentazione.
\end{note}


Osservazione: vale

\[ (\rho + \sigma)^* \cong \rho^* + \sigma^* \]

E l'isomorfismo è canonico. SCRIVI DIMOSTRAZIONE.





\begin{defn}[Rappresentazione regolare]

\label{defn:rappresentazione regolare}
\end{defn}

\begin{exmp}[La rappresentazione regolare di $S_3$]


\end{exmp}


\begin{thm}

\[\mathcal{R}_G \cong \dsum_i deg(\rho_i) \rho_i \]

\end{thm}



\subsection{Sottospazi invarianti e scomposizione delle rappresentazioni}


\begin{defn}[Sottospazio invariante]
NON VA MESSO TUTTO ASSIEME NELLA DEFINIZIONE DI SOTTORAPPRESENTAZIONE???

\end{defn}

\begin{defn}[Sottorappresentazione]
Sia $\rho$ una rappresentazione di $G$ su $V_{\rho}$, una sottorappresentazione di $\rho$ è un sottospazio vettoriale $W\subseteq V_{\rho}$ tale che $\rho(s)(W)\subseteq W\ \forall\ s\in G$. Posso definire una rappresentazione $\sigma$ con $V_{\sigma}=W$ e $\sigma(s)=\rho(s)|_W$ (la indicherò con $\sigma\subseteq \rho$).
\end{defn}



\begin{defn}[Rappresentazione irriducibile]
Una rappresentazione $\rho$ di $G$ è \textit{irriducibile} se
\begin{enumerate}
	\item $\rho \neq 0$ ($deg(\rho) \geq 1$)
	\item $\rho$ non ha sottorappresentazioni non banali (diverse da 0 e $V_{\rho}$).
\end{enumerate}

\end{defn}

\begin{rem} Normalmente la cosa che si fa più spesso in teoria della rappresentazione è cercare di scomporre la rappresentazione di un gruppo come somma di rappresentazioni irriducibili. Vedremo quindi adesso diversi teoremi che ci aiuteranno in questi problemi.

\end{rem}



\begin{exmp}[Rappresentazione regolare di $S_3$]


\end{exmp}



\begin{thm}[Le rappresentazioni di un gruppo finito sono completamente riducibili]

\end{thm}

\begin{prop}[Prodotto hermitiano invariante]

\end{prop}


\begin{lemma}
Sia $h: V_\rho \times V_\rho \to \C$ una forma hermitiana definita positiva e invariante per $\rho: G \to GL(V_\rho)$ e sia $\rho|_W: G \to GL(W)$ una sottorappresentazione di $\rho$. Allora se $W^\perp$ è l'ortogonale di $W$, $\rho|_{W^\perp}: G \to GL(W^\perp)$ è una sottorappresentazione.




\end{lemma}






\begin{lemma}
Sia $\rho: G \to GL(V_\rho)$ una rappresentazione di un gruppo finito $G$. Sia $\rho|_W: G \to GL(W)$ una sottorappresentazione di $\rho$. Allora esiste una sottorappresentazione $\sigma: G \to GL(W')$ tale che

\[\rho = \rho|_W + \sigma \]
\end{lemma}






\begin{rem} Notare che il teorema precedente è falso per gruppi finiti. (Esempio con $\mathbb{Z}^+$ che Salvatore non ha scritto con cura. Porco salvatore)



\end{rem}



\begin{thm} Se $\rho: G \to GL(V_\rho)$ e $\sigma: G \to GL(V_\sigma)$ sono rappresentazioni di $G$ e $f: V_\rho \to V_\sigma$ è un omomorfismo di rappresentazioni, allora $Im(f)$ è una sottorappresentazione di $\sigma$ e $Ker(f)$ è una sottorappresentazione di $V_\rho$
\end{thm}
\begin{proof}
Se $v\in Ker(f)$ allora per la definizione di omomorfismo di rappresentazioni ho che $\forall s\in G$ $f(\rho(s)v)=\sigma(s)f(v)=0$ e quindi $\rho(s)v\in Ker(f)$. Allo stesso modo, se $w\in Im(f)$ allora $w=f(v)$ per qualche $v\in V_\rho$ e quindi sempre per la definizione di omomorfismo di rappresentazione $\sigma(s)w=\sigma(s)f(v)=f(\rho(s)v)\in Im(f)$
\end{proof}




\begin{thm}Sia $G$ un gruppo abeliano finito. Allora ogni rappresentazione di $G$ è isomorfa alla somma di rappresentazioni di grado 1.



\end{thm}


\begin{prop} La rappresentazione regolare $\mathcal{R}$ di $C_n$ è isomorfa alla somma delle $n$ rappresentazioni irriducibili di grado 1 di $C_n$.

\end{prop}


\begin{lemma}
Date $\rho_1, \rho_2, \sigma$ rappresentazioni di $G$, allora

\[Hom(\rho_1 + \rho_2, \sigma) \cong Hom(\rho_1, \sigma) \oplus Hom(\rho_2, \sigma)\]

\end{lemma}


\begin{thm}[Lemma di Schur]
Siano $\rho$ e $\sigma$ due rappresentazioni irriducibili di $G$ gruppo finito e $\phi:\rho\to\sigma$ un omomorfismo di rappresentazioni, allora $\phi$ è un isomorfismo oppure è identicamente nullo. Se poi $f:\rho\to\rho$ è un omomorfismo di rappresentazioni, allora $f$ è una moltiplicazione per scalare.
\end{thm}
\begin{proof}
Supponiamo che $\phi\neq0$, allora sappiamo che $Ker(\phi)\subseteq V_\rho$ è una sottorappresentazione di $\rho$, ma $\rho$ è irriducibile e quindi $Ker(\phi)=0\Rightarrow \phi$ iniettiva. Ma anche $Im(\phi)\subseteq V_{\sigma}$ è una sottorappresentazione di $\sigma$ e, non essendo nulla ed essendo $\sigma$ irriducibile, coincide con tutto $V_\sigma \Rightarrow \phi$ suriettiva, da cui $\phi$ è un isomorfismo.
Consideriamo ora $f$: sia $\lambda$ un autovalore di $f$, che esiste perché $G$ è finito e stiamo lavorando su $\C$, allora $f-\lambda Id:V_\rho\to V_\rho$ è un omomorfismo di rappresentazioni. Ma non è iniettivo, perché c'è almeno un autovettore relativo a $\lambda$, e quindi per la prima parte del lemma di Schur ho che $f-\lambda Id$ è identicamente nullo, da cui ricaviamo che $f$ è la moltiplicazione per uno scalare ($\lambda$).
\end{proof}


\begin{thm}
Sia $\rho: G \to GL(V_\rho)$ una rappresentazione e 

\[\rho = \dsum_{i=1}^N n_i \rho_i \]

una sua scomposizione come somma di rappresentazioni irriducibili a due a due non isomorfe. Allora la scomposizione è unica.
\end{thm}



\begin{lemma}
Sia $\rho$ una rappresentazione di $G$ e $\mathcal{R}$ la sua rappresentazione regolare. Allora 
\[deg(\rho) = dim(Hom(\mathcal{R}, \rho))\]
\end{lemma}




\begin{thm}
Sia $\mathcal{R}$ la rappresentazione regolare di $G$, un gruppo finito, e sia 

\[ \mathcal{R} = \dsum_{i=1}^Nn_i \rho_i\]

Con $\rho_i$ irriducibili e a due a due non isomorfe. Allora ogni rappresentazione irriducibile di $G$ è isomorfa ad una $\rho_i$. Inoltre $n_i = deg(\rho_i)$ 
\label{thm: teorema importantissimo}
\end{thm}



\begin{cor}
Se $G$ è abeliano allora ha $|G|$ rappresentazioni irriducibili di grado 1 e $\mathcal{R}$ è la somma di queste.
\end{cor}



\begin{cor}
Sia $G$ un gruppo finito. $G$ ha un numero finito di rappresentazioni irriducibili, a meno di isomorfismi. Inoltre
\[|G| = \dsum n_i^2\]
\end{cor}



















\newpage
\section{Teoria dei caratteri}


\begin{defn}
Sia $\rho: G \to GL(V_\rho)$ una rappresentazione di un gruppo $G$. Definiamo carattere di $\rho$ la funzione che associa ad ogni elemento del gruppo $G$ la traccia della matrice associata all'elemento, ovvero

\[\chi_\rho(s) := tr (\rho(s)) \qquad \forall s \in G \]
Notare che $\chi_{\rho}$ è una funzione che va dal gruppo in $\C$, ovvero $\chi_{\rho}: G \to \C$

\end{defn}

Vediamo delle proprietà elementari del carattere

\textsc{Osservazioni:}
\begin{enumerate}
	\item Se $deg(\rho) = 1$ allora il carattere di $s$ è uguale a $\rho(s)$
	\item $\chi_{\rho_1} = deg(\rho)$. \footnote{Al solito $\rho_1$ è la rappresentazione che manda ogni elemento nell'identità di $V_\rho$}\\
	Questo è vero poichè $[\rho_1]=I_n\Rightarrow tr(\rho_1)=n$ ed $n=deg(\rho)$.
	\item $\chi_{\rho + \sigma}(s) = \chi_\rho(s) + \chi_\sigma(s)$.\\ 
	Questo è dovuto al fatto che la somma di rappresentazioni si può scrivere come matrice a blocchi. Una volta scritto così è evidente il risultato.
	\item $\chi_{\rho\sigma}(s) = \chi_\rho(s)\chi_\sigma(s)$.\\ 
	Questo deriva dal seguente fatto generale:
	
\begin{lemma} 
Se $f: V \to V$ e $g: W \to W$ sono endomorfismi di spazi vettoriali, allora $tr(f \otimes g) = tr(f)tr(g)$.
\end{lemma}
\textbf{Dimostrazione:} Iniziamo a considerare il caso in cui sia $f$ che $g$ siano diagonalizzabili: prendendo due basi $a:I\rightarrow V$ , $b:J\rightarrow W$ di autovettori rispettivamente per $f$ e per $g$, si verifica facilmente la verità della proposizione nella base indotta su $V\otimes W$ (ovvero in quella formata dagli $a_i\otimes b_j$).\\
Ora, essendo la traccia una funzione continua e le matrice diagonalizzabili dense nello spazio delle matrici, la proprietà affermata dal lemma si estende al caso generale per continuità.
	\item $\chi_{\rho}(s^{-1})=\overline{\chi_{\rho}(s)}$\\
Essendo $G$ un gruppo finito, $\forall s\in G\ \rho(s)^n = id$ dove $n=|G|$: dunque tutti gli autovalori di $\rho(s)$ sono radici ennesime dell'unità e $\rho(s)$ è diagonalizzabile\footnote{Si veda la proposizione \ref{prop:diagonalizzabilita rappresentazioni}}. In tale base è evidente che:
$$\chi_{\rho}(s^{-1})=tr(\rho (s^{-1}))=tr(\rho (s)^{-1})=\sum_i\lambda_i^{-1}=\sum_i\overline{\lambda_i}=\overline{tr(\rho(s))}=\overline{\chi_{\rho}(s)}$$
in quanto, avendo gli autovalori modulo 1, l'inverso coincide con il coniugio.  	
	\item $\chi_{\rho^*}(s)\footnote{Ricordiamo che $\rho^*(s) = (\rho(s)^{-1})^*$} = \overline{\chi_\rho(s)}$.\\
		Per l'osservazione precedente vale che
		$$\chi_{\rho^*}(s)=tr(^t\rho(s^{-1}))=tr(\rho(s^{-1}))=\overline{tr(\rho(s))}=\overline{\chi_\rho(s)}$$
	\item $\chi_{\rho}(hsh^{-1})=\chi_{\rho}(s)$ ovvero $\chi_\rho$ è costante sulle classi di coniugio di $G$. La motivazione è semplice: se due elementi sono coniugati tra loro questo significa che le matrici corrispondenti saranno simili e la traccia è un invariante di similitudine.
	
Di conseguenza, non sarà necessario calcolare il carattere per ogni elemento del gruppo ma basterà farlo per le classi di coniugio di $G$.

Le funzioni che costanti sulle classi di coniugio di un gruppo vengono dette $funzioni\ di\ classe$. L'insieme delle funzioni di classe di un gruppo viene normalmente indicato con $Cl(G)$ e si verifica che esso è un sottospazio di $\mathbb{C}^G$.
	\item Supponiamo di avere una rappresentazione per permutazioni. Sia $I$ un insieme finito e $G$ un gruppo allora 
$$\chi_{\rho_{I}}(s)=\#punti\ fissi\ di\ \rho_I(s)=|I^s|$$
dove $I^s:=\{i\in I| s\circ i=i\}$. La veridicità di questo fatto si vede scrivendo esplicitamente la matrice che rappresenta $\rho_I(s)$.
	\item Consideriamo la rappresentazione per permutazioni regolare $R$. Calcoliamone il carattere:
	\[ \chi_{\mathcal{R}}(s) = \begin{cases}
|G| \qquad \text{se } s=id \\
0 \qquad \text{se } s\neq id\\
\end{cases} \]
semplicemente perchè $s\circ g=g\Leftrightarrow s=id$.
\end{enumerate}
\textbf{Esempio:} $G=S_3$, $I=\{1,2,3\}$. Allora

\[ \chi_{\rho_I}(s) = \begin{cases}
3 \qquad \text{se } s=id \\
1 \qquad \text{se } s\ \text{è una trasposizione}\\
0 \qquad \text{se } s\ \text{è un treciclo}\\
\end{cases} \]
Ricordandoci che $\chi_{\rho_I}=\chi_{1+\rho}$ si ha che 
\[ \chi_{\rho}(s) = \begin{cases}
2 \qquad \ \ \text{se } s=id \\
0 \qquad \ \ \text{se } s\ \text{è una trasposizione}\\
-1\qquad \text{se } s\ \text{è un treciclo}\\
\end{cases} \]

\begin{defn}[Prodotto hermitiano dei caratteri]

\[ \langle f | g \rangle = \dfrac{1}{|G|} \dsum_{s \in G} f(s)\overline{ g(s)} \]

\end{defn}


\begin{thm}[Relazioni di ortogonalità]
Se $\rho$ e $\sigma$ sono rappresentazioni irriducibili di $G$, allora vale

\[\langle \chi_{\rho}|\chi_{\sigma} \rangle = \begin{cases}
1 \qquad \text{se } \rho \cong \sigma \\
0 \qquad \text{altrimenti }\\
\end{cases} \]
\label{relazione di ortogonalita}
\end{thm}

Per dimostrare questo teorema abbiamo bisogno di un lemma che ora enunciamo e dimostriamo.




\begin{lemma}
Se $(\rho, V_\rho)$ e $(\sigma, V_\sigma)$ sono rappresentazioni \footnote{Non necessariamente irriducibili} di $G$, allora vale

\[ \langle \chi_\rho | \chi_\sigma \rangle  = dim(Hom (\sigma, \rho))\] 
\label{lemma relazioni ortogonalita}
\end{lemma}
\textsc{Dimostrazione:}

L'idea principale per dimostrare questo lemma è di ridurci al caso più facile in cui una delle due rappresentazioni è quella banale. Per farlo notiamo un paio di cose

\[ \langle \chi_\rho | \chi_\sigma \rangle = \dfrac{1}{|G|} \dsum_{s\in G} \overline{\chi_\rho(s)} \chi_\sigma(s) = \dfrac{1}{|G|} \dsum_{s\in G} {\chi_{\rho^*}(s)} \chi_\sigma(s) = \dfrac{1}{|G|} \dsum_{s\in G} \chi_{\rho^*\sigma}(s)  = \langle \chi_{\rho^*\sigma} \rangle | 1\]

Siamo passati da due rappresentazioni ad una sola. In particolare lo spazio vettoriale su cui agisce questa rappresentazione è 

\[ V_{\rho^* \sigma} = V_{\rho}^* \otimes V_\sigma \cong Hom(V_\rho, V_\sigma)\]

E questo isomorfismo segue semplicemente dalle proprietà del prodotto tensore di spazi vettoriali. Notiamo che sullo spazio degli omomorfismi\footnote{Dato che sono spazi vettoriali in questo caso si tratta semplicemente di applicazioni lineari} $Z = Hom(V_\rho, V_\sigma)$ è possibile definire una rappresentazione completamente analoga a $\rho\sigma^*$ in questo modo: se $f \in Z$, allora possiamo definire la rappresentazione $\tau, V_\tau = Z$ di $G$ in questo modo

\[ \tau(s)f = \rho(s) \circ f \circ \sigma^{-1}(s)\]

\'E possibile mostrare che se chiamo $\Psi$ la mappa tale che

\[
\begin{cases}
V_\rho^* \otimes V_\sigma \xrightarrow{\Psi} Hom(V_\rho, V_\sigma)\\
\rho\sigma^* \xrightarrow{\Psi} \tau \\
\end{cases}
\]

Allora $\Psi$ è un isomorfismo di rappresentazioni. Dimostriamolo rapidamente. Innanzitutto definiamo in modo esplicito $\Psi$. Basterà definirlo per i tensori decomponibili, per il resto dello spazio basterà estenderlo per linearità.

\[ \Psi(\phi \otimes v ) (w) = \phi(w) v \qquad \forall \phi \in V_\rho^*, \forall v \in V_\sigma, \forall w \in V_\rho\]

Per mostrare che è un isomorfismo di rappresentazioni ci basta mostrare che ha la giusta proprietà di commutazione in quanto sappiamo già che $\Psi$ è un isomorfismo di spazi vettoriali. Vediamo quindi di mostrare che 

\[\Psi(\tau(s)\cdot (\phi \otimes v))(w) = \tau(s) \cdot \Psi(\phi \otimes v)(w) \qquad \forall s \in G \quad \text{eccetera} \]


Partiamo dal membro di sinistra e facciamo i calcoli


\[\Psi(\tau(s)\cdot (\phi \otimes v))(w) = \Psi\left( \rho(s) (\phi \otimes v ) \sigma(s)^{-1}  \right)(w)  = \]

\[= \Psi((\phi \circ \sigma(s)^{-1})\otimes (\rho(s) v) )(w) =  \]

\[ = (\phi \circ \sigma(s)^{-1}) (w) \rho(s) v = \phi(\sigma(s)^{-1} w) \rho(s) v\]

\[ = \rho(s)\phi(\sigma(s)^{-1} w) v = \rho(s) \Psi(\phi \otimes v) \sigma(s)^{-1} (w) = \tau(s) \Psi (\phi \otimes v)(w)\]


A questo punto possiamo andare a cercare i sottospazi invarianti per $\tau$, ovvero stiamo andando a cercare le sottorappresentazioni irriducibili di $\tau$ sperando di usare teoremi che già conosciamo. In particolare stiamo quindi cercando dei sottospazi $W \subset Z = Hom(V_\rho, V_\sigma)$ tali che $\tau(s) W \subset W \quad \forall s \in G$ 

In particolare, cerchiamo le funzioni $f \in Hom(V_\sigma, V_\rho)$ tali che $\tau(s) f = f$. Dalla definizione di $\tau$ si vede che

\[f = \tau(s) f =  \rho(s) \circ f \circ \sigma^{-1}(s) \Rightarrow  f \sigma(s)= \rho(s) f\] 


Ovvero le applicazioni $f$ invarianti per $\tau $ sono gli omomorfismi di rappresentazioni da $(\rho, V_\rho) $ a $(\sigma, V_\sigma)$

A questo punto

\[ (V_{\sigma^*\rho})^G \cong Hom(V_\sigma, V_\rho)^G \cong Hom(\sigma, \rho)\]

Per cui dato che noi stiamo cercando $dimHom(\sigma, \rho)$, basterà trovare $dim(V_{\sigma^*\rho})^G$

Visto che ci siamo ricondotti al caso in cui una rappresentazione è banale, ora facciamo i conti cercando di trovare la dimensione dello spazio invariante per $G$. Scriviamo la definizione di quello che vogliamo calcolare


\[ \langle \chi_\rho | 1 \rangle = \dfrac{1}{|G|} \dsum_{s \in G} tr \rho(s)\]

Se definiamo l'operatore $T$ come operatore lineare

\[ T = \dfrac{1}{|G|} \dsum_{s\in G} \rho(s)\]


Allora si nota che 

\[ \rho(t) Tv = \dfrac{1}{|G|} \dsum_{s\in G} \rho(t)\rho(s) v = \dfrac{1}{|G|} \dsum_{s\in G} \rho(s) = Tv\]

Per cui sappiamo che $V_\rho^G \subseteq ImT$. L'obiettivo è mostrare che quella non è una disuguaglianza ma un'uguaglianza. In realtà questa è la disuguaglianza stupida in quanto se $v \in V_\rho^G$ allora è chiaro che $Tv = v$, basta applicare la definizione. Per cui $ImT = V_\rho^G$. A questo punto vogliamo calcolare la sua traccia. Per farlo notiamo che 

\[T(Tv) = \ldots = Tv \qquad \text{Verifica banale}\]

Per cui $T$ è un proiettore. A questo punto sappiamo dall'algebra lineare che

\[ V_\rho = Ker T \oplus Im T = Ker T \oplus V_\rho^G\]

Per cui $trT = dimImT = dimV_\rho^G$. Ma dalla catena di deduzioni che abbiamo fatto

\[dimHom(V_\sigma, V_\rho) = dim(V_{\sigma^*\rho}^G) = trT = \langle \chi_{\sigma^*\rho} | 1 \rangle = \langle \chi_\sigma | \chi_\rho \rangle\]

\qed














\textsc{Dimostrazione del teorema \ref{relazione di ortogonalita}:}

A questo punto la tesi del teorema \ref{relazione di ortogonalita} segue dal lemma precedente applicato insieme al lemma di Schur. \qed


\textsc{Osservazioni:}

\begin{itemize}
\item Ricordiamo che se $\rho$ è una rappresentazione di $G$, allora $\rho$ si può scrivere in modo unico come 

\[ \rho = \dsum_i n_i \rho_i\]

Dove le $\rho_i$ sono le rappresentazioni irriducibili di $G$ e gli $n_i$ sono numeri naturali $\geq 0$. Dall'equazione scritta sopra segue subito che

\[ \chi_\rho = \dsum_i n_i \chi_{\rho_i}\]

E possiamo ottenere un'informazione utile prendendo il prodotto scalare dell'equazione precedente con il carattere di una delle rappresentazioni $\rho_i$

\[ \langle \chi_\rho | \chi_{\rho_j} \rangle = \dsum_i n_i \langle \chi_{\rho_i} | \chi_{\rho_j} \rangle \Rightarrow n_i \delta_{ij} = \langle \chi_\rho | \chi_{\rho_j} \rangle \Rightarrow n_i = \langle \chi_\rho | \chi_{\rho_i} \rangle\]

\item Caso particolare interessante del fatto precedente riguarda la rappresentazione regolare di un gruppo. Difatti come sappiamo,

\[ \chi_{\mathcal{R}}(s) = 
\begin{cases}
|G| \quad \text{se } s = e \\
0 \quad \text{altrimenti}
\end{cases}\]
Quindi considerando una sottorappresentazione  si ha che 
\[
\langle \chi_{\mathcal{R}} | \chi_\rho \rangle = \frac{1}{|G|}|G|\chi_{\rho}(id)=\chi_{\rho}(id)=deg(\rho)
\]
In particolare se $\rho$ è una sottorappresentazione irriducibile allora
\[ deg(\rho)=dim(Hom(\mathcal{R},\rho)) \]
Quindi ottengo una conferma del teorema precedente 
\[      
\langle \chi_{\mathcal{R}} | \chi_\rho \rangle =dim(Hom(\mathcal{R},\rho))
\]

\item Se $\rho$ e $\sigma$ sono 2 rappresentazioni irriducibili allora $$\rho \cong \sigma \Leftrightarrow \chi_{\rho}=\chi_{\sigma}$$

\item $\langle \chi_\rho | \chi_\rho \rangle = |\chi_\rho|^2 = \sum_i n_i^2$.
\item Conseguenza dell'ultima osservazione è che una rappresentazione di un gruppo $\rho$ è irriducibile $\Leftrightarrow \langle \chi_\rho | \chi_\rho \rangle = |\chi_\rho|^2 = 1$ 


\end{itemize}




\begin{cor}[Corollario del lemma \ref{lemma relazioni ortogonalita}: Lemma di Burnside]

Consideriamo un'azione di un gruppo $G$ su un insieme $I$ e consideriamo una rappresentazione dell'azione di $G$, $(\rho_I, V_{\rho_I})$. Consideriamo

\[\langle \chi_{\rho_I} | 1 \rangle = \dfrac{1}{|G|} \dsum_{s\in G} tr \rho_I(s)\]

Ma è ovvio che 

\[tr \rho_I(s) = |I^s| \qquad I^s = \{ i \in I | s \cdot i = i\} \]

Per cui lo spazio $V_{\rho_I}^G = \{\dsum a_i e_i | \text{Alcune condizioni}\}$ sarà composto da i vettori che hanno i coefficienti $a_i$ costanti su ciascuna orbita di $G$ su $I$, proprio per lasciarlo invariante. Perciò 

\[ dimV_{\rho_I}^G = \text{numero delle orbite } = |I/G|\]

E con l'affermazione precedente si ottiene appunto il lemma di Burnside

\[ |I/G| = \dfrac{1}{|G|} \dsum_{s\in G} |I^s|\]

\qed
\end{cor}



\begin{thm} Sia $G$ un gruppo finito e siano $\rho_1, \ldots , \rho_r$ le sue rappresentazioni irriducibili. Sia inoltre 

\[Cl(G)  \]

Lo spazio delle funzioni da $G$ in $\C$ costanti sulle classi di coniugio di $G$

Chiaramente $dimCl(G) = $ numero di classi di coniugio di $G$ $:= s$. La tesi del teorema è che $r = s$ dove $r$ è il numero di rappresentazioni irriducibili. 

\textsc{Osservazione:} Per questo motivo la tabella dei caratteri sarà una tabella quadrata

\end{thm}

\textsc{Dimostrazione:}
 DA SCRIVERE


















\subsection{Tabella dei caratteri}


Dato un gruppo $G$, possimo costruire la $tabella\ dei\ caratteri$ nel seguente modo:
\begin{itemize}
\item su ogni colonna mettiamo un rappresentante della classe di coniugio con sotto la cardinalità dell'orbita ovvero

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c}
\hline
$G$  & $e$ & $orb(g_1)$ & $orb(g_2)$ & \\
 & 1 & $|orb(g_1)|$ & $|orb(g_2)|$ & \\
\hline
 & &  & \\
\end{tabular}
\end{table}

\item su ogni riga mettiamo una rappresentazione irriducibile del gruppo
\item all'incrocio tra la rappresentazione $\rho_i$ e la classe di coniugio di $g_j$ inseriamo il valore di $\chi_{\rho_i(g_j)}$.


\end{itemize}



\subsection{Esempi di rappresentazioni di gruppi finiti}

\begin{exmp}[Tabella dei caratteri di $S_3$] 
La prima cosa da fare per costruire la tabella dei caratteri è vedere quanti elementi ha $S_3$, suddividerli in classi di coniugio e poi cercare le rappresentazioni irriducibili solo dopo aver fatto tutto questo. Notiamo subito che $S_3$ ha esattamente 3 classi di coniugio. La prima è ovviamente quella banale, composta solo dall'identità $e$. Poi c'è la classe delle trasposizioni $\{(1 2) ,(2 3), (1 3)\}$ che ha 3 elementi e poi ci sono i $3$cicli, ovvero $(1 2 3)$ e $(1 3 2)$. Possiamo cominciare a scrivere una tabella vuota $3\times 3$


\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
$S_3$  & $e$ & $(1 2)$ & (1 2 3 )  \\
 & 1 & 3 & 2 \\
\hline
 & &  & \\
\hline
& &  & \\
\hline
& &  & \\
\hline
\end{tabular}
\end{table}



Una rappresentazione irriducibile che c'è sempre è la rappresentazione banale di grado 1, ovvero quella che manda ogni elemento nell'identità. La tabella con questa informazione diventa



\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
$S_3$  & $e$ & $(1 2)$ & (1 2 3 )    \\
 & 1 & 3 & 2 \\
\hline
 $\rho_1$ & 1 & 1  & 1 \\
\hline
& &  & \\
\hline
& &  & \\
\hline
\end{tabular}
\end{table}


Un'altra rappresentazione che già conosciamo è il segno, $\epsilon$, che ricordiamo vale $(-1)^{n-1}$ dove $n$ è la lunghezza del ciclo. La tabella diventa




\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
$S_3$  & $e$ & $(1 2)$ & (1 2 3 )    \\
 & 1 & 3 & 2 \\
\hline
 $\rho_1$ & 1 & 1  & 1 \\
\hline
$\epsilon$ & 1 & -1 & 1 \\
\hline
& &  & \\
\hline
\end{tabular}
\end{table}

A questo punto ci sono due motivi per dire che l'ultima rappresentazione ha grado 2: il primo è che è l'unico modo di ottenere la relazione

\[ |G | = \dsum_i n_i^2 \]

Il secondo è che se fossero due rappresentazioni di grado 1 allora il gruppo avrebbe solo rappresentazioni irriducibili di grado 1 e un teorema che abbiamo fatto implicherebbe che $S_3$ sia abeliano, cosa palesemente falsa. 

Per trovare il carattere dell'ultima rappresentazione possiamo agire in più modi. Innanzitutto la tabella ora ha la forma




\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
$S_3$  & $e$ & $(1 2)$ & (1 2 3 )    \\
 & 1 & 3 & 2 \\
\hline
 $\rho_1$ & 1 & 1  & 1 \\
\hline
$\epsilon$ & 1 & -1 & 1 \\
\hline
$\rho$ & 2 &  & \\
\hline
\end{tabular}
\end{table}


In generale ci saranno due numeri complessi $a, b$ nelle due caselle che mancano. Tuttavia noi sappiamo un sacco di teoremi che ci permettono di restringere il campo dei valori che possono avere. Per esempio noi sappiamo che 

\[\langle \rho_i | \rho_j \rangle = \delta_{ij}\]
 
Per cui imponendo che il prodotto scalare con entrambe le precedenti faccia 0 abbiamo due equazioni e due incognite, ovvero un problema risolvibile. L'altro modo è dire che

\[ \mathcal{R} = 1 + \epsilon + 2\rho\]

E dato che il carattere si comporta bene con la somma di rappresentazioni, 

\[\chi_{\mathcal{R}} = \chi_1 + \chi_\epsilon + 2 \chi_\rho  \]

Ma sappiamo anche che 

\[ \chi_{\mathcal{R}}(s) = 
\begin{cases}
|G| \quad \text{se } s = e \\
0 \quad \text{altrimenti}
\end{cases}\]

Per cui con agili conti riusciamo a completare la tabella








\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
$S_3$  & $e$ & $(1 2)$ & (1 2 3 )    \\
 & 1 & 3 & 2 \\
\hline
 $\rho_1$ & 1 & 1  & 1 \\
\hline
$\epsilon$ & 1 & -1 & 1 \\
\hline
$\rho$ & 2 & 0 & 1 \\
\hline
\end{tabular}
\caption{Tabella dei caratteri di $S_3$}
\label{tabella caratteri s3}
\end{table}

L'ultimo modo è cercare di scomporre un'altra rappresentazione a caso di $S_3$, cercando di trovare la rappresentazione che ci manca. Per esempio ricordiamo l'azione di $S_3$ sui vettori di base di $\mathbb{R}^3$

\[ \tau(s) e_i = e_{s(i)}\]

Ricordiamo che il sottospazio di dimensione $1$ fatto dallo span del vettore $v = e_1 + e_2 + e_3$ è un sottospazio invariante in cui $\tau(s)$ è sostanzialmente l'identità. Il suo ortogonale è un altro sottospazio invariante su cui $\rho$ è irriducibile. Di conseguenza potremo scrivere

\[ \tau = 1 + \rho\]

E siamo sicuri che l'altra rappresentazione di grado 2 sia esattamente quella che stiamo cercando proprio grazie al teorema che ci dice che tutte le rappresentazioni irriducibili di un gruppo compaiono nella sua rappresentazione regolare. (Teorema \ref{thm: teorema importantissimo})

Dato che è facile calcolare il carattere di $\tau(s)$ in quanto è uguale a $Fix(s)$, possiamo scrivere

\[ Fix(s) = 1 + \chi_\rho\]

Da cui si ricava subito il carattere della rappresentazione $\rho$



\end{exmp}






\begin{exmp}[Tabella dei caratteri di $S_4$]
Facciamo la prima cosa importante: dividiamo $S_4$ in classi di coniugio. Per i soliti teoremi sugli $S_n$, le classi di coniugio saranno 
\[\{e\}, \{(a b)\}, \{(a b c)\}, \{(a b c d)\}, \{(a b)(c d)\}\]

E notiamo che sono 5. Possiamo quindi cominciare a compilare la tabella dei caratteri vuota



\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$S_4$  & $e$ & $(1 2)$ & (1 2 3 ) & $(1 2 3 4)$ & $(1 2)(3 4)$ \\
 & 1 & 6 & 8 & 6 & 3 \\
\hline
 $\rho_1$ & 1 & 1  & 1 & 1 & 1\\
\hline
& &  & & & \\
\hline
& &  & & & \\
\hline
& &  & & & \\
\hline
& &  & & & \\
\hline
\end{tabular}
\end{table}


dove ho già messo la rappresentazione banale. Anche per $S_4$, essendo un gruppo simmetrico c'è la rappresentazione segno di grado 1. 




\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$S_4$  & $e$ & $(1 2)$ & (1 2 3 ) & $(1 2 3 4)$ & $(1 2)(3 4)$ \\
 & 1 & 6 & 8 & 6 & 3 \\
\hline
 $\rho_1$ & 1 & 1  & 1 & 1 & 1\\
\hline
$\epsilon$ & 1  & -1 & 1 & -1 & 1 \\
\hline
& &  & & & \\
\hline
& &  & & & \\
\hline
& &  & & & \\
\hline
\end{tabular}
\end{table}


A questo punto bisogna fare cose a caso cercando le rappresentazioni irriducibili. Per esempio possiamo di nuovo considerare la rappresentazione per permutazioni



\[ \tau(s) e_i = e_{s(i)}\]


Che si scompone anche questa come

\[ \tau = 1 + \rho\]

Vorremmo sapere se $\rho$ è irriducibile. Potremmo invocare qualche teorema ma lo faremo con le mani calcolando il carattere di $\rho$


\[ \chi_\rho(s) = Fix(s) - 1 = 
\begin{cases}
3 \quad \text{Se } s = e \\
1 \quad \text{Se } s = (a b) \\
0 \quad \text{Se } s = (a b c) \\
-1 \quad \text{Se } s = (a b c d ), (a b) (c d)\\
\end{cases}
\]

E andando a calcolare

\[\langle\chi_\rho |\chi_\rho\rangle = \dfrac{1}{24}\left(3^2  + 6 \cdot 1^2  + 0 + (-1)^2 \cdot (3 +6 )\right) = 1\]
 

Per cui è effettivamente irriducibile.  Aggiungiamola alla tabella.


\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$S_4$  & $e$ & $(1 2)$ & (1 2 3 ) & $(1 2 3 4)$ & $(1 2)(3 4)$ \\
 & 1 & 6 & 8 & 6 & 3 \\
\hline
 $\rho_1$ & 1 & 1  & 1 & 1 & 1\\
\hline
$\epsilon$ & 1  & -1 & 1 & -1 & 1 \\
\hline
$\rho$& 3 & 1 & 0 & -1 & -1\\
\hline
& &  & & & \\
\hline
& &  & & & \\
\hline
\end{tabular}
\end{table}

Abbiamo appena terminato le rappresentazioni che conoscevamo di $S_4$.\\
\textbf{Ottimo consiglio:} Quando non vengono in mente altre rappresentazioni, considera due già presenti nella tabella e fanne il prodotto. Risulta utile il seguente lemma.

\begin{lemma}
Se $\rho$ e $\sigma$ sono due rappresentazioni e $deg(\rho)=1$ ( ovvero $\rho:G\rightarrow \mathbb{C}^*$), allora $\sigma$ è irriducibile $\Leftrightarrow$ $\rho\sigma$ lo è. Inoltre hanno lo stesso grado.
\end{lemma}

\textbf{Dimostrazione:} Che sia ancora a tutti gli effetti una rappresentazione si verifica esplicitamente sapendo che
\[
\forall s\in G \rho\sigma(s)=\rho(s)\sigma(s)
\]
Per dimostrare che è irriducibile si considera il fatto che
\[
\sigma \ irriducibile\ \Leftrightarrow 1=\langle\chi_{\sigma}|\chi_{\sigma}\rangle=\frac{1}{|G|}\sum_{s\in G}|\chi_{\sigma(s)}|^2
\]
Quindi...
\[
\langle \chi_{\rho\sigma}|\chi_{\rho\sigma}\rangle=\frac{1}{|G|}\sum_{S\in G}|\chi_{\rho\sigma(s)}|^2=\frac{1}{|G|}\sum_{s\in G}|\chi_{\rho(s)}\chi_{\sigma(s)}|^2=\frac{1}{|G|}|\rho(s)\chi_{\sigma(s)}|^2=\frac{1}{|G|}\sum_{s\in G}|\rho(s)|^2|\chi_{\sigma(s)}|^2
\]
ed essendo $\rho(s)$ una radice $n-$esima dell'unità dove $n$ è l'ordine di $G$ si ha che 
\[1 | 
\langle \chi_{\rho\sigma}|\chi_{\rho\sigma}\rangle=\frac{1}{|G|}\sum_{s\in G}
|\chi_{\sigma(s)}|^2=\langle \chi_{\sigma}|\chi_{\sigma}\rangle
\]
Che abbiano lo stesso grado deriva dal fatto che
\[
\chi_{\rho\sigma}=\chi_{\rho}\chi_{\sigma}\Rightarrow deg(\rho\sigma)=\chi{\rho\sigma}(id)=\chi_{\rho}(id)\chi_{\sigma}(id)=deg(\rho)deg(\sigma)=deg(\sigma).
\] \\
Essendo $\epsilon$ di grado 1 e $\rho$ irriducibile allora anche $\rho\epsilon$ è un'altra rappresentazione irriducibile.


\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$S_4$  & $e$ & $(1 2)$ & (1 2 3 ) & $(1 2 3 4)$ & $(1 2)(3 4)$ \\
 & 1 & 6 & 8 & 6 & 3 \\
\hline
 $\rho_1$ & 1 & 1  & 1 & 1 & 1\\
\hline
$\epsilon$ & 1  & -1 & 1 & -1 & 1 \\
\hline
$\rho$& 3 & 1 & 0 & -1 & -1\\
\hline
$\rho\epsilon$& 3 & -1 & 0 & 1 & -1\\
\hline
& &  & & & \\
\hline
\end{tabular}
\end{table}


E a questo punto dato che $|S_4|=24$ e che $1+1+3^2+3^2=20$ si possono avere due situazioni: $S_4$ potrebbe avere ancora 4 rappresentazioni irriducibili di grado 1 oppure solo più una di grado 2. Tuttavia abbiamo visto come $S_n$ ammetta solo due rappresentazioni irriducibili di grado 1 quindi siamo nel secondo caso.\\
Dato che ce ne manca solo una possiamo usare il trucco di prima (differenza dalla rappresentazione $R$ ) e concludere:

\begin{table}[!ht] 
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline
$S_4$  & $e$ & $(1 2)$ & (1 2 3 ) & $(1 2 3 4)$ & $(1 2)(3 4)$ \\
 & 1 & 6 & 8 & 6 & 3 \\
\hline
 $\rho_1$ & 1 & 1  & 1 & 1 & 1\\
\hline
$\epsilon$ & 1  & -1 & 1 & -1 & 1 \\
\hline
$\rho$& 3 & 1 & 0 & -1 & -1\\
\hline
$\rho\epsilon$& 3 & -1 & 0 & 1 & -1\\
\hline
 $\sigma$& 2&  0 & -1& 0 & 2\\
\hline
\end{tabular}
\caption{Tabella dei caratteri di $S_4$}
\label{tabella caratteri s4}
\end{table}


\textbf{Ossevazione:} Guardiamo la tabella, in particolare il "minore" ottenuto considerando le prime due e l'ultima riga e le prime 3 colonne. 

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
$S_4$  & $e$ & $(1 2)$ & (1 2 3 )    \\
 & 1 & 6 & 8 \\
\hline
 $\rho_1$ & 1 & 1  & 1 \\
\hline
$\epsilon$ & 1 & -1 & 1 \\
\hline
$\sigma$ & 2 & 0 & 1 \\
\hline
\end{tabular}
\end{table}
Se la confrontiamo con la tabella dei caratteri di $S_3$ vediamo che sono analoghe. Intuitivamente $\rho$ in $S_3$ deriva dalla rappresentazione $\sigma$ di $S_4$ mediante un omomorfismo 
\[
S_4\rightarrow S_3
\]
che corrisponde ad una azione di $S_4$ su un insieme di 3 elementi. Tale insieme è il sottogruppo di Klein privato dell'unità ovvero
\[
\{ (12)(34),(13)(24),(14)(23)\}
\]
\\
In questo caso non è servito ma potremmo trovarci in una situazione in cui i seguenti lemmi si rivela utile
\begin{lemma}
$\rho^* $ è irriducibile $ \Leftrightarrow \rho$ è irriducibile.
\end{lemma}
Infatti $\chi_{\rho^*}=\overline{\chi_\rho} $ e quindi analogamente al lemma precedente si vede che
\[
1=\langle\chi_{\rho}|\chi_{\rho}\rangle \Leftrightarrow 1=\langle\chi_{\rho^*}|\chi_{\rho^*}\rangle
\]

\begin{lemma}
Se $\rho$ è una rappresentazione di grado $d$ di $G$, come sempre gruppo finito, allora:\\
$(a)$ $|\chi_{\rho}(s)|\leq d$ \\
$(b)$ Direttamente dal punto $(a)$ si decude che, 
\[
\chi_{\rho}(s)=d\Leftrightarrow \lambda_1,...,\lambda_d=1\Leftrightarrow \rho(s)=id
\]
dove $\lambda_1,..,\lambda_d$ sono gli autovalori della matrice $[\rho(s)]$.
\end{lemma}
\textbf{Dimostrazione:} Se $\lambda_1,..,\lambda_d$ sono gli autovalori della matrice $[\rho(s)]$ allora $\chi_{\rho}(s)=\sum_{i=1}^{d}\lambda_i$. Inoltre essendo $G$ finito $|\lambda_i|=1\forall i\in \{1,...,d\}$. Se ne deduce che
\[
|\chi_{\rho}(s)|\leq \sum_{i=1}^d |\lambda_i|=d
\]



\end{exmp}





\begin{exmp}[Tabella dei caratteri di $D_5$]

La prima cosa da fare è dividere $D_5$ in classi di coniugio


FINIRE

\end{exmp}



\subsubsection{I problemi della prima lezione visti con i nuovi strumenti}
\begin{exmp}[Problema 1 prima lezione]


\end{exmp}

\begin{exmp}[Problema 2 prima lezione]


\end{exmp}

\begin{exmp}[Problema 3 prima lezione]

Consideriamo un cubo. Scriviamo un numero su ciascuna delle facce e consideriamo l'operazione $T$ che per ogni faccia sostituisce al numero presente la media dei numeri presenti sulle 4 facce del cubo adiacenti. Vogliamo studiare il comportamento dei numeri del cubo quando questa iterazione viene compiuta molte volte.


Cerchiamo di formalizzare il problema usando la teoria della rappresentazione. Possiamo considerare l'insieme $F$ delle facce del cubo\footnote{Che ha quindi 6 elementi}. Una generica configurazione del cubo sarà esprimibile come 

\[ v = \dsum_{f \in F} a_f e_f \]

Dove $a_f \in \mathbb{C}$ e $e_f$ sono una base. L'operatore che sostituisce la media è lineare ma soprattuto commuta con le simmetrie del problema. Ora spiegherò meglio questo concetto.

Consideriamo il gruppo $G$ delle rotazioni del cubo, ovvero 

\[G = \{ g \in SO(3) | g(Cubo) \subset Cubo \} \]

\'E ovvio che il problema è invariante per simmetria, ovvero se $g \in G$, allora vale

\[ T v = g^{-1}T g v \]

Che è la formula di un cambio di base. Questo si può scrivere come 

\[gT = Tg \]

Ovvero ci dice che $\forall g \in G$ le due operazioni commutano. Le due frasi precedenti sono state dette un po' alla garibaldina in quanto non è $g$ ad agire sul cubo ma è una sua rappresentazione di grado $|F| = 6$. Di conseguenza è bene scrivere in modo formale che $\tau: G \to GL(V_\tau)$ è una rappresentazione del gruppo di rotazioni del cubo in $\mathbb{C}^6$ e questa rappresentazione commuta con un operatore $T$, ovvero

\[T\tau(g) = \tau(g) T \qquad \forall g \in G  \]


L'obiettivo che ci poniamo ora è quello di riuscire a scomporre $\tau$ come somma di rappresentazioni irriducibili in quanto una volta trovata una scomposizione 

\[ V_\tau = \bigoplus_{i = i}^n V_{\rho_i} \] 

Allora potremo usare il lemma di Schur per dire che su ogni $V_{\rho_i}$ l'operatore $T$ si comporta come scalare ovvero \emph{è più che diagonalizzato}. Per riuscire a capire qualcosa di come sono fatte le rappresentazioni di questo gruppo è opportuno prima cercare di dare una struttura più chiara a questo gruppo.

\'E possibile mostrare che QUALCUNO CHE HA VOGLIA DI FARLO LO FACCIA PLS $G \cong S_4$. A questo punto noi abbiamo una rappresentazione di grado 6 di $S_4$ che cerchiamo di scomporre come somma di rappresentazioni irriducibili. Tuttavia grazie al teorema \ref{thm: teorema importantissimo} sappiamo che tutte le sottorappresentazioni di $\tau$ saranno isomorfe alle sottorappresentazioni della rappresentazione regolare $\mathcal{R}(S_4)$, di cui abbiamo preventivamente calcolato la tabella dei caratteri \ref{tabella caratteri s4}. Dato che 


\[\tau = \dsum_i n_i\rho_i \Rightarrow \chi_\tau  = \dsum_i n_i\chi_{\rho_i}\]

Andiamo a calcolare i prodotti scalari dei caratteri delle rappresentazioni irriducibili di $S_4$ con il carattere di $\tau$ per trovare quali rappresentazioni compaiono. Per farlo calcoliamo prima il carattere di $\tau$


SCRIVI CHE NON HO VOGLIA

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|c|c|c|}
\hline


\end{tabular}
\end{table} 



Per cui si ottiene

\[\tau = 1 + \epsilon\rho + \sigma \]

Ovvero

\[V_\tau = V_1 \oplus V_{\epsilon\rho} \oplus V_{\sigma} \]


Cerchiamo quindi di capire come sono fatti questi tre spazi che hanno rispettivaemente dimensione 1,3,2. 


SCRIVI PI\'U DETTAGLIATO CHE DEVO ANDARE A LEZIONE

\[V_1 =  span(e_1 + e_2 + ... + e_6) \]
\[V_{\epsilon\rho} = \text{Le facce opposte hanno numeri opposti}\]
\[V_{\sigma} = \text{Le facce opposte hanno numeri uguali e la somma di tutti è 0}\]

Su questi spazi è facile vedere che effettivamente $T$ è scalare. In particolare

\[
\begin{cases}
T|_{V_1} = 1 \\
T|_{V_{\epsilon\rho}} = 0 \\
T|_{V_\sigma} = -\frac{1}{2}\\
\end{cases}
\]

E quindi è evidente che $T^n \to $ su ogni faccia viene la media dei numeri che c'erano all'inizio.


\end{exmp}











\newpage
\section{Rappresentazioni reali, complesse e quaternioniche}

Ci poniamo un problema nuovo: quand'è che una rappresentazione, che abbiamo sempre definito su $\C$, funziona in modo uguale anche definendola solo su $\R$? Diamo una definizione più precisa

\begin{defn}
Diciamo che una rappresentazione $(\rho, V_\rho$ del gruppo $G$ è reale se esiste una base di $V_\rho$ tale che

\[ \rho(g) \in M_n(\R) \ \ \forall g \in G\]

\label{def: rappr reale}
\end{defn}

\begin{exmp}
Prendiamo come gruppo un gruppo ciclico, per esempio $\Z / 3\Z$\footnote{Che per i fisici è isomorfo a $C_3$}. Evidentemente tutte le rappresentazioni non banali di $G$ non sono reali, in quanto sono di grado 1 e sono le radici dell'unità.

\end{exmp}


\begin{rem}
Supponiamo di avere $\rho: G \to GL(V_\rho)$ con $V_\rho$ spazio vettoriale su $\C$ di dimensione $n$ (dimensione complessa). Allora possiamo definire  $V_\R$ uno spazio vettoriale su $\R$ (che avrà dimensione $2n$) e lavorare su quello, se il nostro obiettivo è quello di avere una rappresentazione reale.

Equivalentemente, $\exists V_0 \subset V$ reale tale che QUI HO PERSO UN PEZZO SUGLI APPUNTI, QUALCUNO COMPLETI, 

\[ V = \C \otimes_\R V_0 = V_0 \oplus i V_0\]

\end{rem}




\begin{rem}
Se $\rho$ è irriducibile su $\C$, se prendo la sua versione reale definita come prima non è detto che rimanga irriducibile.

\end{rem}


Ora andremo a fare una classificazione delle rappresentazioni. Vedremo che ne esistono di 3 tipi:
\begin{itemize}
\item Reali
\item Complesse
\item Quaternioniche
\end{itemize}



La classificazione verrà fatta in base all'esistenza o meno di forme bilineari di un certo tipo invarianti sotto $G$. Vediamo come farlo formalmente.


\begin{thm}

Prendiamo una rappresentazione $(\rho, V_\rho)$ di $G$ reale, definita come in \ref{def: rappr reale}. Allora lo spazio vettoriale $V_\rho$ possiede una forma bilineare simmetrica invariante sotto l'azione della rappresentazione di $G$.

\end{thm}

\textsc{Dimostrazione:} Abbiamo supposto la rappresentazione reale. Esisterà quindi $V_0$, spazio vettoriale reale su cui agisce la rappresentazione. Sicuramente su questo spazio esiste una qualsiasi forma bilineare simmetrica $B_0$ non degenere

\[ B_0 \in S^2 V_0^*\]

Possiamo ora renderla invariante sotto l'azione di $G$ con il solito metodo del fare la media. Consideriamo quindi $\tilde B_0$ definito come


\[ \tilde B_0(v_1, v_2) = \dfrac{1}{|G|} \dsum_{g\in G} B_0(\rho(g) v_1, \rho(g) v_2)\]




Questo ha le caratteristiche precedenti ed è anche invariante sotto $G$. Possiamo a questo punto estenderla a forma bilineare su $V$ complessificandola in modo ovvio. Consideriamo quindi $B$

\[B \in (S^2V^*)^G \]

che definiamo sullo spazio $V = V_0 \oplus i V_0$ 

\[B(v_1 + i v_1', v_2 + i v_2') = \left( \tilde B_0(v_1, v_2) - \tilde B_0(v_1', v_2')\right)  + i \left( \tilde B_0(v_1', v_2) + B_0(v_1, v_2')\right)\]




\'E una banale verifica controllare che rispetta le caratteristiche richieste.
\qed


Vediamo ora il seguente lemma che ci servirà per la classificazione.

\begin{lemma}
Sia $(\rho, V_\rho)$ una rappresentazione di un gruppo $G$ su uno spazio vettoriale complesso. Allora esiste una forma bilineare non nulla invariante e non degenere. Questa forma è unica a meno di scalare.
\end{lemma}

\textsc{Dimostrazione:}

Prendiamo un elemento $B$

\[B \in \left(V^* \otimes V^*\right)^G \]

\'E un fatto di algebra che 

\[\left(V^* \otimes V^*\right)^G \cong Hom(V, V^*)^G \]

A questo punto, se $\phi: V\to V^*$ è un omomorfismo di rappresentazioni, o $\phi$ è nullo o $\phi = \lambda Id$. Dato che la forma è non nulla, allora $\phi = \lambda Id$  \qed 


Consideriamo un caso particolare per chiarire le idee. Vediamo per esempio quand'è che la forma non è solo nulla, ovvero si ha $\left(V^* \otimes V^*\right)^G \neq 0$

QUALCUNO LO SCRIVA CON PAROLE PI\'U CHIARE

\[ \left(V^* \otimes V^*\right)^G \neq 0 \Leftrightarrow Hom(V, V^*) ^G \neq 0 \Leftrightarrow \rho \cong \rho^* \Leftrightarrow \chi_\rho = \chi_{\rho^*} \Leftrightarrow \chi_{\rho} = \overline{\chi_{\rho}} \Leftrightarrow \chi_\rho \in \R\]


Andiamo ora finalmente ad effettuare la nostra classificazione sulle rappresentazioni. Prima di farlo ricordiamo rapidamente il seguente fatto: SCRIVI LA DECOMPOSIZIONE IN SIMMETRICO E ALTERNO




\begin{lemma}
\begin{itemize}
\item Sia $(\rho, V_\rho)$ una rappresentazione di $G$ su campo complesso. Allora 

\[ B \in (V^* \otimes V^*)^G \Rightarrow B \in S^2V^* \vee B \in \bigwedge ^2 V^*\]

\item Definiamo 

\[ m_\rho = \dfrac{1}{|G|} \dsum_{g \in G} \chi_{\rho}(g^2)\]

l'indicatore di Frobenius-Schur. Allora

\[ m_\rho \in \{-1, 0, 1 \} \]

\item{ \begin{enumerate}

\item se $m_\rho = 0 \Rightarrow (V^*\otimes V^*)^G = 0$
\item se $m_\rho = 1 \Rightarrow (S^2 V^*)^G \neq 0$
\item se $m_\rho = -1 \Rightarrow (\bigwedge^2 V^*)^G \neq 0$
\end{enumerate}
}

\end{itemize}
\end{lemma}



\textsc{Dimostrazione:}

QUALCUNO LA SCRIVA


\begin{defn}[Classificazione sull'indice di Frobenius]

\begin{itemize}
\item Se $m_\rho = 1$ la rappresentazione si dice \textbf{reale}
\item Se $m_\rho = 0$ la rappresentazione si dice \textbf{complessa}
\item Se $m_\rho = -1$ la rappresentazione si dice \textbf{quaternionica}
\end{itemize}
\end{defn}


\subsection{Quaternioni}

Ovviamente la parola quaternionica ha a che fare con il corpo dei quaternioni. Vediamo un po' di caratteristiche interessanti di questo oggetto.

Il corpo $\HH$ si può vedere come

\[\HH = \R \oplus i \R \oplus j \R \oplus k \R \]

Con $i,j,k$ unità immaginarie che rispettano le seguenti regole

\[ 
\begin{cases}
i^2 = j^2 = k^2 = -1 \\
ij = - ji = k \\
jk = -kj = i \\
ki = - ik = j \\
\end{cases}
\]


Vediamo un po' di proprietà interessanti. Per esempio se consideriamo 

\[ Q_8 =  \{\pm 1, \pm i, \pm j, \pm k \}\]

allora questo insieme è un gruppo se munito della moltiplicazione. Possiamo andare a vedere la tabella dei caratteri di questo gruppo. 



SCRIVI LA TABELLA DEI CARATTERI



\'E interessante notare che la tabella dei caratteri di $Q_8$ è uguale a quella di $D_4$, ma i due gruppi non sono isomorfi. Questo ci ricorda che la tabella dei caratteri dice tanto di un gruppo ma non tutto.


COSE RANDOM SCRITTE DI FRETTA PERCH\'E devo andare a lezione

\[\HH = \left\{ \left \left(\begin{array}{cc} z & w \\ -\overline{w} & \overline z \end{array}\right) \right| z, w \in \C \right\} \]

























\end{document}
